{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GPU (highly recommended)\n",
    "\n",
    "-> If using `theano` backend:\n",
    "\n",
    "`THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1050 Ti (CNMeM is enabled with initial size: 3.0% of memory, cuDNN 5105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from numpy import nan\n",
    "import keras\n",
    "\n",
    "print keras.__version__\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 5\n",
    "nb_epoch = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train, test, nb_classes):\n",
    "    \n",
    "    X_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(train[1], nb_classes)\n",
    "    Y_test = np_utils.to_categorical(test[1], nb_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# create two datasets one with digits below 5 and one with 5 and above\n",
    "X_train_lt5 = X_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "X_test_lt5 = X_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "X_train_gte5 = X_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5  # make classes start at 0 for\n",
    "X_test_gte5 = X_test[y_test >= 5]         # np_utils.to_categorical\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", input_shape=(28, 28, 1...)`\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "# define two groups of layers: feature (convolutions) and classification (dense)\n",
    "feature_layers = [\n",
    "    Convolution2D(nb_filters, kernel_size, kernel_size,\n",
    "                  border_mode='valid',\n",
    "                  input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Convolution2D(nb_filters, kernel_size, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(nb_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (30596, 28, 28, 1))\n",
      "(30596, 'train samples')\n",
      "(5139, 'test samples')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/5\n",
      "30596/30596 [==============================] - 6s - loss: 0.2184 - acc: 0.9342 - val_loss: 0.0541 - val_acc: 0.9815\n",
      "Epoch 2/5\n",
      "30596/30596 [==============================] - 6s - loss: 0.0745 - acc: 0.9767 - val_loss: 0.0274 - val_acc: 0.9905\n",
      "Epoch 3/5\n",
      "30596/30596 [==============================] - 6s - loss: 0.0488 - acc: 0.9852 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 4/5\n",
      "30596/30596 [==============================] - 6s - loss: 0.0375 - acc: 0.9889 - val_loss: 0.0142 - val_acc: 0.9951\n",
      "Epoch 5/5\n",
      "30596/30596 [==============================] - 6s - loss: 0.0339 - acc: 0.9898 - val_loss: 0.0124 - val_acc: 0.9957\n",
      "Training time: 0:03:34.903606\n",
      "('Test score:', 0.012447581390064992)\n",
      "('Test accuracy:', 0.9957190114808329)\n"
     ]
    }
   ],
   "source": [
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model,\n",
    "            (X_train_lt5, y_train_lt5),\n",
    "            (X_test_lt5, y_test_lt5), nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (29404, 28, 28, 1))\n",
      "(29404, 'train samples')\n",
      "(4861, 'test samples')\n",
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 0s - loss: 0.3808 - acc: 0.8850 - val_loss: 0.0913 - val_acc: 0.9708\n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 0s - loss: 0.1313 - acc: 0.9597 - val_loss: 0.0606 - val_acc: 0.9809\n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 0s - loss: 0.0990 - acc: 0.9694 - val_loss: 0.0474 - val_acc: 0.9835\n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 0s - loss: 0.0818 - acc: 0.9748 - val_loss: 0.0424 - val_acc: 0.9858\n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 0s - loss: 0.0741 - acc: 0.9773 - val_loss: 0.0372 - val_acc: 0.9877\n",
      "Training time: 0:00:07.915863\n",
      "('Test score:', 0.03715517895759483)\n",
      "('Test accuracy:', 0.9876568606178889)\n"
     ]
    }
   ],
   "source": [
    "# freeze feature layers and rebuild model\n",
    "for l in feature_layers:\n",
    "    l.trainable = False\n",
    "\n",
    "# transfer: train dense layers for new classification task [5..9]\n",
    "train_model(model,\n",
    "            (X_train_gte5, y_train_gte5),\n",
    "            (X_test_gte5, y_test_gte5), nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to Fine Tune a VGG16 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Softmax.0, inputs=flatten/fl...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 33,617,733\n",
      "Trainable params: 33,617,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "model_vgg16_conv.summary()\n",
    "\n",
    "#Create your own input format (here 3x200x200)\n",
    "inp = Input(shape=(48,48,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(inp)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(5, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=inp, output=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "...\n",
    "...\n",
    "# Plugging new Layers\n",
    "    model.add(Dense(768, activation='sigmoid'))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(768, activation='sigmoid'))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29404, 48, 48, 3)\n",
      "('X_train shape:', (29404, 48, 48, 3))\n",
      "(29404, 'train samples')\n",
      "(29404, 'test samples')\n",
      "(60000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29404/29404 [==============================] - 203s - loss: 1.6217 - acc: 0.2112   \n",
      "Epoch 2/5\n",
      "29404/29404 [==============================] - 204s - loss: 1.6086 - acc: 0.2131   \n",
      "Epoch 3/5\n",
      "29404/29404 [==============================] - 204s - loss: 1.6086 - acc: 0.2131   \n",
      "Epoch 4/5\n",
      "29404/29404 [==============================] - 204s - loss: 1.6085 - acc: 0.2131   \n",
      "Epoch 5/5\n",
      "29404/29404 [==============================] - 204s - loss: 1.6085 - acc: 0.2131   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5935632cd0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "new_shape = (48,48)\n",
    "X_train_new = np.empty(shape=(X_train_gte5.shape[0],)+(48,48,3))\n",
    "\n",
    "for idx in xrange(X_train_gte5.shape[0]):\n",
    "    X_train_new[idx] = np.resize(scipy.misc.imresize(X_train_gte5[idx], (new_shape)), (48, 48, 3))\n",
    "    X_train_new[idx] = np.resize(X_train_new[idx], (48, 48, 3))\n",
    "    \n",
    "#X_train_new = np.expand_dims(X_train_new, axis=-1)\n",
    "\n",
    "print X_train_new.shape\n",
    "\n",
    "X_train_new = X_train_new.astype('float32')\n",
    "X_train_new /= 255\n",
    "    \n",
    "print('X_train shape:', X_train_new.shape)\n",
    "print(X_train_new.shape[0], 'train samples')\n",
    "print(X_train_new.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train_gte5, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test_gte5, nb_classes)\n",
    "\n",
    "print y_train.shape\n",
    "\n",
    "my_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "my_model.fit(X_train_new, Y_train,\n",
    "              batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              verbose=1)\n",
    "\n",
    "#print('Training time: %s' % (now() - t))\n",
    "#score = my_model.evaluate(X_test, Y_test, verbose=0)\n",
    "#print('Test score:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "#train_model(my_model,\n",
    "#            (X_train_new, y_train_gte5),\n",
    "#            (X_test_gte5, y_test_gte5), nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
